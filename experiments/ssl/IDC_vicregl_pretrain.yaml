imports: "$import pickle"
version: "lr=dynamic_global_grid_size=[3,10,10]_new_efficientnet"

CONSTANTS:
  HIGH_RES_SIZE: [96, 320, 320]  # [128, 400, 400]
  HIGH_RES_GRID_SIZE: [3, 10, 10]
  LOW_RES_SIZE: [32, 96, 96]  # [32, 128, 128]
  LOW_RES_GRID_SIZE: [1, 3, 3]

project: /home/ibrahim/Projects/lighter/projects/lighter-ct-fm

trainer:
  _target_: pytorch_lightning.Trainer
  benchmark: True
  max_epochs: 1000
  limit_train_batches: 100
  accelerator: gpu
  #
  devices: 2
  strategy: ddp_find_unused_parameters_true
  sync_batchnorm: True
  #
  precision: 16-mixed
  log_every_n_steps: 10
  logger: False
  callbacks:
    # - _target_: lighter.callbacks.logger.LighterLogger
    - _target_: project.callbacks.ssl_logger.SSLLogger
      project: IDC_vicregl_pretrain
      log_dir: $f"/mnt/data16/IDC_SSL_CT/runs/logs/IDC_vicregl_pretrain/{@version}"
      wandb: True
      # input_type: image
      # pred_type:
      #   - "embedding_histogram"
      #   - null
      #   - null
      #   - null
      # max_samples: 10

    - _target_: pytorch_lightning.callbacks.ModelCheckpoint
      dirpath: $f"/mnt/data16/IDC_SSL_CT/runs/checkpoints/IDC_vicregl_pretrain/{@version}"
      save_last: True
      verbose: True
      every_n_epochs: 10
      save_weights_only: True

system:
  _target_: lighter.LighterSystem
  batch_size: 4
  pin_memory: True
  drop_last_batch: True # Used in SSL cases because of negatives
  num_workers: 8 # 32

  model:
    _target_: project.models.vicregl.VICRegL
    num_ftrs: 1792
    spatial_dims: 3
    backbone:
      _target_: project.models.efficientnet.EfficientNetForPretraining
      model_name: efficientnet-b4
      pretrained: False
      spatial_dims: 3
      in_channels: 1
  
  criterion:
    _target_: project.loss.vicregl.VICRegLLoss
    gather_distributed: True

  optimizers:
    _target_: torch.optim.AdamW
    params: "$@system#model.parameters()"
    # Learning rate calculated as per: `lr = (effective_batch_size) / 256 * base_lr`
    # Calculated based on the paper's effective_batch_size=384 and lr=0.001
    lr: "$((@system#batch_size * @trainer#devices)/256) * 0.0007"
    weight_decay: 0.000001
  
  schedulers:
    _target_: monai.optimizers.WarmupCosineSchedule
    optimizer: "@system#optimizers"
    warmup_steps: 50  # First 50 epochs
    t_total: $@trainer#max_epochs


  train_metrics: null
  val_metrics: "%system#train_metrics"
  test_metrics: "%system#train_metrics"
  

  train_dataset:
    _target_: project.datasets.safe_dataset_wrapper.SafeDatasetWrapper
    disable: False
    dataset:
      _target_: project.datasets.idc_ssl.IDCDataset
      image_files: "$pickle.load(open('/mnt/data16/IDC_SSL_CT/scan_list.pkl', 'rb'))"  # "$list(pathlib.Path('/mnt/data16/IDC_SSL_CT/scans/').rglob('scan.nrrd'))"
      transform:
        _target_: monai.transforms.Compose
        transforms:
          - _target_: monai.transforms.LoadImage
            image_only: True
          - _target_: monai.transforms.EnsureChannelFirst
          - _target_: monai.transforms.Orientation
            axcodes: "LPS"
          - _target_: monai.transforms.Transpose
            indices: [0, 3, 2, 1] # cxyz -> czyx
          - _target_: monai.transforms.CropForeground
          - _target_: monai.transforms.ScaleIntensityRange
            a_min: -1024
            a_max: 3072
            b_min: 0
            b_max: 1
            clip: True
          - _target_: monai.transforms.SpatialPad
            spatial_size: "@CONSTANTS#HIGH_RES_SIZE"
          - _target_: monai.transforms.ToTensor
          - _target_: project.transforms.ssl.MultiCrop
            high_resolution_transforms:
              - _target_: monai.transforms.Compose
                transforms:
                  # This transform produces a dict, we start using MONAI's dict transforms after it.
                  - _target_: project.transforms.vicregl.RandomResizedCropAndFlip3D
                    roi_size: "@CONSTANTS#HIGH_RES_SIZE"
                    grid_size: "@CONSTANTS#HIGH_RES_GRID_SIZE"
                  - # RandHistogramShift serves purpose similar to color jitter by modifying the intensity histogram
                    _target_: monai.transforms.RandHistogramShiftd
                    keys: image
                    prob: 0.5
                  - # RandGaussianSmooth is similar to SimCLR GaussianBlur
                    _target_: monai.transforms.RandGaussianSmoothd
                    keys: image
                    prob: 0.5
                  - _target_: monai.transforms.SelectItemsd
                    keys: ["image", "grid"]
                  - _target_: monai.transforms.ToTensord
                    keys: ["image", "grid"]
                    track_meta: False
              - "%#0"
            low_resolution_transforms: null
              # - _target_: monai.transforms.Compose
              #   transforms:
              #     # This transform produces a dict, we start using MONAI's dict transforms after it.
              #     - _target_: project.transforms.vicregl.RandomResizedCropAndFlip3D
              #       roi_size: "@CONSTANTS#LOW_RES_SIZE"
              #       grid_size: "@CONSTANTS#LOW_RES_GRID_SIZE"
              #     - # RandHistogramShift serves purpose similar to color jitter by modifying the intensity histogram
              #       _target_: monai.transforms.RandHistogramShiftd
              #       keys: image
              #       prob: 0.5
              #     - # RandGaussianSmooth is similar to SimCLR GaussianBlur
              #       _target_: monai.transforms.RandGaussianSmoothd
              #       keys: image
              #       prob: 0.5
              #     - _target_: monai.transforms.ToTensord
              #       keys: ["image", "grid"]
              #       track_meta: False
              # - "%#0"
              # - "%#0"
              # - "%#0"
              # - "%#0"
              # - "%#0"
          # - _target_: project.transforms.monai_related.AddNoneTarget
  val_dataset: null
  test_dataset: null
