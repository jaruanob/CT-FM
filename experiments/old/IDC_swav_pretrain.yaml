imports: "$import pathlib"
vars:
  HIGH_RES_SIZE: [96, 320, 320]  # [128, 400, 400]
  LOW_RES_SIZE: [32, 64, 64]  # [32, 128, 128]

project: /home/ibrahim/Projects/lighter/projects/lighter-ct-fm

trainer:
  _target_: pytorch_lightning.Trainer
  benchmark: True
  max_epochs: 1000
  limit_train_batches: 100
  accumulate_grad_batches: 64
  accelerator: gpu
  #
  devices: 1
  # strategy: ddp
  # sync_batchnorm: True
  #
  precision: 16-mixed
  log_every_n_steps: 10
  logger: False
  callbacks:
    - _target_: lighter.callbacks.logger.LighterLogger
      project: IDC_full_swav_pretrain
      log_dir: /home/ibrahim/Projects/lighter/projects/lighter-ct-fm/logs/IDC_swav_pretrain
      wandb: True
      input_type: "image"
      max_samples: 1
    - _target_: pytorch_lightning.callbacks.ModelCheckpoint
      dirpath: "/home/ibrahim/Projects/lighter/projects/lighter-ct-fm/checkpoints/IDC_swav_pretrain"
      save_last: True
      verbose: True
      every_n_epochs: 10
      save_weights_only: True

system:
  _target_: lighter.LighterSystem
  batch_size: 4
  pin_memory: True
  drop_last_batch: True # Used in SSL cases because of negatives
  num_workers: 8 # 32
  
  model:
    _target_: project.models.swav.SwaV
    num_ftrs: 1792
    out_dim: 128
    n_prototypes: 256 # 512
    n_queues: 2
    queue_length: 256 # 512  # this one is an interesting one
    start_queue_at_epoch: 10  # SwaV starts at the 15th *epoch* in the paper
    n_steps_frozen_prototypes: 100
    backbone:
      _target_: lighter.utils.model.replace_layer_with_identity
      layer_name: _fc
      model:
        _target_: lighter.utils.model.replace_layer_with_identity
        layer_name: _swish
        model:
          _target_: monai.networks.nets.EfficientNetBN
          model_name: efficientnet-b4
          pretrained: False
          spatial_dims: 3
          in_channels: 1
  
  criterion:
    _target_: project.loss.swav.SwaVLoss
    temperature: 0.1
    sinkhorn_iterations: 3
    sinkhorn_epsilon: 0.03 # 0.05
    sinkhorn_gather_distributed: "$@trainer.strategy == 'ddp'"

  optimizers:
    # _target_: torch.optim.Adam
    # lr: 5e-5 # 5e-4
    # weight_decay: 1e-4

    _target_: torch.optim.SGD
    params: "$@system#model.parameters()"
    lr: 1.5
    weight_decay: 0.000001
    momentum: 0.9
  
  
  schedulers:
    # scheduler:
    #   _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
    #   factor: 0.9
    #   min_lr: 0.00001
    #   patience: 20
    # interval: step
    # frequency: 1
    # monitor: train/loss
    # strict: True
    _target_: torch.optim.lr_scheduler.CosineAnnealingLR # WarmRestarts
    optimizer: "@system#optimizers"
    T_max: "@trainer#max_epochs"
    eta_min: 0.0001



  train_metrics: null
  val_metrics: "%system#train_metrics"
  test_metrics: "%system#train_metrics"
  
  train_dataset:
    _target_: project.datasets.safe_dataset_wrapper.SafeDatasetWrapper
    dataset:
      _target_: monai.data.ImageDataset  # project.datasets.image_dataset.ImageDataset 
      image_files: "$list(pathlib.Path('/mnt/data16/IDC_SSL_CT/scans/').glob('**/scan.nrrd'))"
      #reader: NrrdReader

      transform:
        _target_: monai.transforms.Compose
        transforms:
          - _target_: monai.transforms.EnsureChannelFirst
          - _target_: monai.transforms.Orientation
            axcodes: "LPS"
          - _target_: monai.transforms.Transpose
            indices: [0, 3, 2, 1] # cxyz -> czyx
          - _target_: monai.transforms.CropForeground
          - _target_: monai.transforms.ScaleIntensityRange
            a_min: -1024
            a_max: 3072
            b_min: 0
            b_max: 1
            clip: True
          - _target_: project.transforms.ssl.MultiCrop
            high_resolution_transforms:
              - _target_: monai.transforms.Compose
                transforms:
                  - _target_: project.transforms.monai_related.FilteredRandSpatialCrop # monai.transforms.RandSpatialCrop
                    allowed_empty_voxel_proportion: 0.3
                    roi_size: "@vars#HIGH_RES_SIZE"
                    random_size: False
                  - _target_: monai.transforms.RandFlip
                    prob: 0.25
                    spatial_axis: 2
                  - # RandHistogramShift serves purpose similar to color jitter by modifying the intensity histogram
                    _target_: monai.transforms.RandHistogramShift
                    prob: 0.5
                  - # RandGaussianSmooth is similar to SimCLR GaussianBlur
                    _target_: monai.transforms.RandGaussianSmooth
                    prob: 0.5
                  - _target_: monai.transforms.SpatialPad
                    spatial_size: "@vars#HIGH_RES_SIZE"
                  - _target_: monai.transforms.ToTensor
                    track_meta: False
              - "%#0"
            low_resolution_transforms:
              - _target_: monai.transforms.Compose
                transforms:
                  - _target_: project.transforms.monai_related.FilteredRandSpatialCrop # monai.transforms.RandSpatialCrop
                    allowed_empty_voxel_proportion: 0.3
                    roi_size: "@vars#LOW_RES_SIZE"
                    random_size: False
                  - _target_: monai.transforms.RandFlip
                    prob: 0.25
                    spatial_axis: 2
                  - # RandHistogramShift serves purpose similar to color jitter by modifying the intensity histogram
                    _target_: monai.transforms.RandHistogramShift
                    prob: 0.5
                  - # RandGaussianSmooth is similar to SimCLR GaussianBlur
                    _target_: monai.transforms.RandGaussianSmooth
                    prob: 0.5
                  - _target_: monai.transforms.SpatialPad
                    spatial_size: "@vars#LOW_RES_SIZE"
                  - _target_: monai.transforms.ToTensor
                    track_meta: False
              - "%#0"
              - "%#0"
              - "%#0"
  val_dataset: null
  test_dataset: null
