project: .
_requires_:
  - "$import monai"
  - "$import torch"
vars:
    init_LR: 0.0002
    num_classes: 9
    intensity_range: [-1000, 200]
    size: "$[96, 128, 128] if @vars#format == 'lighter' else [128, 128, 96]"
    in_channels: 1
    embedding_dim: 512
    cache_dir: '$f"/mnt/data1/suraj/lighter_cache/radchest/{@vars#format}"'
    format: "$'suprem' if 'suprem' in @vars#name else 'lighter'"
    # Transforms the RadChest format to either lighter format (SPL, default) or SuPREM format (RAS)
    dataset_specific_transform: "$lambda x: torch.flip(x, [1]) if @vars#format == 'lighter' else torch.flip(x.permute(0, 3, 2, 1), [2, 3])"
    dataset_dir: "/mnt/data1/datasets/RadChestCT"
    save_dir: '$f"/mnt/data1/CT_FM/evaluations/{@vars#project}/checkpoints/{@vars#name}_{@vars#wandb_group}"'

args:
  validate:
    ckpt_path: $f"{@vars#save_dir}/best-v16.ckpt"
  test: "%#validate"

trainer:
    _target_: pytorch_lightning.Trainer
    benchmark: True
    max_epochs: 100
    check_val_every_n_epoch: 1
    accelerator: gpu
    # ---------
    devices: 4
    strategy: ddp
    sync_batchnorm: True
    # ---------
    precision: 16-mixed
    log_every_n_steps: 10
    callbacks:
        - _target_: lighter.callbacks.LighterFreezer
          name_starts_with: ["_orig_mod.trunk"]
          until_epoch: 0
        # - _target_: pytorch_lightning.callbacks.early_stopping.EarlyStopping
        #   monitor: "val/metrics/MultilabelAUROC/epoch"
        #   mode: "max"
        #   patience: 5
        - _target_: pytorch_lightning.callbacks.ModelCheckpoint
          dirpath: "@vars#save_dir"
          save_last: False
          monitor: "val/metrics/MultilabelAUROC/epoch"
          mode: "max"
          filename: "best"
          auto_insert_metric_name: False
          verbose: True
          every_n_epochs: "%trainer#check_val_every_n_epoch"    
    logger:
        _target_: pytorch_lightning.loggers.WandbLogger
        project: "@vars#project"
        name: '$f"{@vars#name}"'
        save_dir: '$f"/mnt/data1/CT_FM/{@vars#project}/logs/{@vars#name}"'

system:
    _target_: lighter.LighterSystem
    batch_size: 32
    pin_memory: True
    num_workers: 8
    model:
        _target_: torch.compile
        model:
            _target_: project.models.wrapper.TrunkHeadWrapper
            trunk: 
            head:
                - _target_: torch.nn.AdaptiveMaxPool3d
                  output_size: [1, 2, 2]
                - _target_: torch.nn.Flatten
                - _target_: torch.nn.Linear
                  in_features: "$@vars#embedding_dim * 4"
                  out_features: 256
                - _target_: torch.nn.ReLU
                - _target_: torch.nn.Dropout
                  p: 0.5
                - _target_: torch.nn.Linear
                  in_features: 256
                  out_features: 128
                - _target_: torch.nn.ReLU
                - _target_: torch.nn.Dropout
                  p: 0.5
                - _target_: torch.nn.Linear
                  in_features: 128
                  out_features: "@vars#num_classes"
            pre_func:  
                - "$lambda x: x[-1]"
            
    criterion:
        _target_: torch.nn.BCEWithLogitsLoss

    optimizer:
        _target_: torch.optim.AdamW
        params: "$@system#model.parameters()"
        lr: "%vars#init_LR"
        weight_decay: 0.05

    # scheduler:
    #   monitor: "val/metrics/MultilabelAUROC/epoch"
    #   scheduler:
    #     _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
    #     optimizer: "@system#optimizer"
    #     mode: "max"
    #     factor: 0.1
    #     patience: 10
    
    scheduler:
        _target_: monai.optimizers.WarmupCosineSchedule
        optimizer: "@system#optimizer"
        warmup_steps: "$@trainer#max_epochs/100"
        end_lr: 0
        warmup_multiplier: 0.1
        t_total: "@trainer#max_epochs"

    metrics:
        train:
            - _target_: torchmetrics.AUROC
              task: multilabel # Note: Change to `binary` for Task 2 and Task 3 and remove num_classes below
              num_labels: "@vars#num_classes"

        val: "%#train"
        test: 
            - _target_: torchmetrics.AUROC
              task: multilabel # Note: Change to `binary` for Task 2 and Task 3 and remove num_classes below
              num_labels: "@vars#num_classes"
            - _target_: torchmetrics.wrappers.ClasswiseWrapper
              metric:
                _target_: torchmetrics.AUROC
                task: multilabel # Note: Change to `binary` for Task 2 and Task 3 and remove num_classes below
                num_labels: "@vars#num_classes"
                average: 'none'
              labels: ["nodule", "mass", "opacity", "consolidation", "atelectasis", "pleural_effusion", "pneumothorax", "pericardial_effusion", "cardiomegaly"]

    datasets:
        train:
            _target_: monai.data.PersistentDataset
            data:
                _target_: project.data.get_radchest_datalist
                data_dir: "%vars#dataset_dir"
                split: train            
            cache_dir: '$f"{@vars#cache_dir}/train"'
            hash_transform: "$monai.data.utils.json_hashing"
            transform: 
                _target_: monai.transforms.Compose
                transforms: 
                    - _target_: monai.transforms.LoadImaged
                      reader: "NumpyReader"
                      keys: ["image"]
                      npz_keys: ["ct"]
                    - _target_: monai.transforms.ToTensord
                      keys: ["image", "label"]
                    - _target_: monai.transforms.EnsureChannelFirstd
                      keys: ["image"]
                    - _target_: monai.transforms.EnsureTyped
                      keys: ["image"]
                    - _target_: monai.transforms.ScaleIntensityRanged
                      keys: ["image"]
                      a_min: "$@vars#intensity_range[0]"
                      a_max: "$@vars#intensity_range[1]"
                      b_min: 0
                      b_max: 1
                      clip: True
                    # Flip for the dataet 
                    - _target_: monai.transforms.Lambdad
                      keys: ["image"]
                      func: "@vars#dataset_specific_transform"
                    - _target_: monai.transforms.CropForegroundd
                      source_key: "image"
                      keys: ["image"]
                      margin: 10
                    - _target_:   monai.transforms.Resized
                      keys: ["image"]
                      spatial_size: "@vars#size"
                      mode: "bilinear"
                    - _target_: monai.transforms.RandAffined
                      keys: ["image"]
                      prob: 0.2
                      rotate_range: [0.26, 0.26, 0.26]
                      scale_range: [0.2, 0.2, 0.2]
                      cache_grid: True
                      padding_mode: constant
                    - _target_: monai.transforms.RandGaussianSmoothd
                      keys: ["image"]
                      prob: 0.2
                      sigma_x: [0.5, 1.0]
                      sigma_y: [0.5, 1.0]
                      sigma_z: [0.5, 1.0]
                    - _target_: monai.transforms.RandScaleIntensityd
                      keys: ["image"]
                      factors: 0.3
                      prob: 0.5
                    - _target_: monai.transforms.RandShiftIntensityd
                      keys: ["image"]
                      offsets: 0.1
                      prob: 0.5
                    - _target_: monai.transforms.RandGaussianNoised
                      keys: ["image"]
                      std: 0.1
                      prob: 0.2
                    - _target_: monai.transforms.Lambda
                      func: '$lambda x: {"input": x["image"].as_tensor(), "target": x["label"].as_tensor().to(dtype=torch.float32)}'
                      track_meta: False

        val: 
            _target_: monai.data.PersistentDataset
            data:
                _target_: project.data.get_radchest_datalist
                data_dir: "%vars#dataset_dir"
                split: val            
            cache_dir: '$f"{@vars#cache_dir}/val"'
            hash_transform: "$monai.data.utils.json_hashing"
            transform: 
                _target_: monai.transforms.Compose
                transforms: 
                    - _target_: monai.transforms.LoadImaged
                      reader: "NumpyReader"
                      keys: ["image"]
                      npz_keys: ["ct"]
                    - _target_: monai.transforms.ToTensord
                      keys: ["image", "label"]
                    - _target_: monai.transforms.EnsureChannelFirstd
                      keys: ["image"]
                    - _target_: monai.transforms.EnsureTyped
                      keys: ["image"]
                    - _target_: monai.transforms.ScaleIntensityRanged
                      keys: ["image"]
                      a_min: "$@vars#intensity_range[0]"
                      a_max: "$@vars#intensity_range[1]"
                      b_min: 0
                      b_max: 1
                      clip: True
                    # Flip for the dataet 
                    - _target_: monai.transforms.Lambdad
                      keys: ["image"]
                      func: "@vars#dataset_specific_transform"
                    - _target_: monai.transforms.CropForegroundd
                      source_key: "image"
                      keys: ["image"]
                      margin: 10
                    - _target_:   monai.transforms.Resized
                      keys: ["image"]
                      spatial_size: "@vars#size"
                      mode: "bilinear"
                    - _target_: monai.transforms.Lambda
                      func: '$lambda x: {"input": x["image"].as_tensor(), "target": x["label"].as_tensor().to(dtype=torch.float32)}'
                      track_meta: False
        test: 
            _target_: monai.data.Dataset
            data:
                _target_: project.data.get_radchest_datalist
                data_dir: "%vars#dataset_dir"
                split: test            
            transform: 
                _target_: monai.transforms.Compose
                transforms: 
                    - _target_: monai.transforms.LoadImaged
                      reader: "NumpyReader"
                      keys: ["image"]
                      npz_keys: ["ct"]
                    - _target_: monai.transforms.ToTensord
                      keys: ["image", "label"]
                    - _target_: monai.transforms.EnsureChannelFirstd
                      keys: ["image"]
                    - _target_: monai.transforms.EnsureTyped
                      keys: ["image"]
                    - _target_: monai.transforms.ScaleIntensityRanged
                      keys: ["image"]
                      a_min: "$@vars#intensity_range[0]"
                      a_max: "$@vars#intensity_range[1]"
                      b_min: 0
                      b_max: 1
                      clip: True
                    # Flip for the dataet 
                    - _target_: monai.transforms.Lambdad
                      keys: ["image"]
                      func: "@vars#dataset_specific_transform"
                    - _target_: monai.transforms.CropForegroundd
                      source_key: "image"
                      keys: ["image"]
                      margin: 10
                    - _target_:   monai.transforms.Resized
                      keys: ["image"]
                      spatial_size: "@vars#size"
                      mode: "bilinear"
                    - _target_: monai.transforms.Lambda
                      func: '$lambda x: {"input": x["image"].as_tensor(), "target": x["label"].as_tensor().to(dtype=torch.float32)}'
                      track_meta: False

    postprocessing:
        metrics:
            pred: # Pred for torchmetrics is (N, C, ...)
                - "$lambda x: torch.sigmoid(x)"

            target:
                # Remove the channel dim. Target for torchmetrics is (N, ...)
                - "$lambda tensor: tensor.long()"
        logging:              
            pred:
                - "$lambda x: x.argmax(dim=1, keepdim=True)"
                - "$lambda x: x.float()"
            target:
                - "$lambda x: x.unsqueeze(1)"
                - "$lambda x: x.float()"