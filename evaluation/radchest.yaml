project: .
CONSTANTS:
    init_LR: 0.0002
    project: "radchest_eval"
    num_classes: 9
    intensity_range: [-1000, 200]
    size: [96, 128, 128]
    in_channels: 1
    embedding_dim: 512
    cache_dir: '$f"/mnt/data1/suraj/lighter_cache/radchest/{@CONSTANTS#format}"'
    format: "$'suprem' if 'suprem' in @CONSTANTS#name else 'lighter'"
    # Transforms the RadChest format to either lighter format (SPL, default) or SuPREM format (RAS)
    dataset_specific_transform: "$lambda x: torch.flip(x, [1]) if @CONSTANTS#format == 'lighter' else torch.flip(x.permute(0, 3, 2, 1), [2, 3])"
    dataset_dir: "/mnt/data1/RadChestCT"

trainer:
    _target_: pytorch_lightning.Trainer
    benchmark: True
    max_epochs: 100
    check_val_every_n_epoch: 1
    accelerator: gpu
    # ---------
    devices: 4
    strategy: ddp_find_unused_parameters_true
    sync_batchnorm: True
    # ---------
    precision: 16-mixed
    log_every_n_steps: 10
    logger:
        _target_: pytorch_lightning.loggers.WandbLogger
        project: "@CONSTANTS#project"
        name: '$f"{@CONSTANTS#name}"'
        save_dir: '$f"/mnt/data1/CT_FM/{@CONSTANTS#project}/logs/{@CONSTANTS#name}"'

system:
    _target_: lighter.LighterSystem
    batch_size: 32
    pin_memory: True
    num_workers: 8
    model:
        _target_: torch.compile
        model:
            _target_: project.models.wrapper.TrunkHeadWrapper
            trunk:
                _target_: lighter.utils.model.adjust_prefix_and_load_state_dict
                ckpt_path: /mnt/data1/CT_FM/IDC_SSL_CT/runs/checkpoints/CT_FM_Reconstruction_SegResNetDS/epoch=79-step=40000.ckpt
                ckpt_to_model_prefix: '${"backbone.encoder" : ""} if "recon" in @CONSTANTS#name else {"backbone.": ""}'
                model:
                    _target_: monai.networks.nets.segresnet_ds.SegResEncoder
                    spatial_dims: 3
                    in_channels: "@CONSTANTS#in_channels"
                    init_filters: 32
                    blocks_down: [1, 2, 2, 4, 4]
            head:
                - _target_: torch.nn.AdaptiveAvgPool3d
                  output_size: 1
                - _target_: torch.nn.Flatten
                - _target_: torch.nn.Linear
                  in_features: "@CONSTANTS#embedding_dim"
                  out_features: "@CONSTANTS#num_classes"
            pre_func:  
                - "$lambda x: x[-1]"
            
    criterion:
        _target_: torch.nn.BCEWithLogitsLoss

    optimizer:
        _target_: torch.optim.AdamW
        params: "$@system#model.parameters()"
        lr: "%CONSTANTS#init_LR"
        weight_decay: 1.0e-05 

    scheduler:
        _target_: torch.optim.lr_scheduler.CosineAnnealingLR
        optimizer: "@system#optimizer"
        T_max: "%trainer#max_epochs"
        eta_min: 0

    metrics:
        train:
            - _target_: torchmetrics.AUROC
              task: multilabel # Note: Change to `binary` for Task 2 and Task 3 and remove num_classes below
              num_labels: "@CONSTANTS#num_classes"

        val: "%#train"
        test: "%#train"

    datasets:
        train:
            _target_: monai.data.PersistentDataset
            data:
                _target_: project.data.radchest_get_image_label_paths
                data_dir: "%CONSTANTS#dataset_dir"
                split: train            
            cache_dir: '$f"{@CONSTANTS#cache_dir}/train"'
            hash_transform: "$monai.data.utils.json_hashing"
            transform: 
                _target_: monai.transforms.Compose
                transforms: 
                    - _target_: monai.transforms.LoadImaged
                      reader: "NumpyReader"
                      keys: ["image"]
                      npz_keys: ["ct"]
                    - _target_: monai.transforms.ToTensord
                      keys: ["image", "label"]
                    - _target_: monai.transforms.EnsureChannelFirstd
                      keys: ["image"]
                    - _target_: monai.transforms.EnsureTyped
                      keys: ["image"]
                    - _target_: monai.transforms.ScaleIntensityRanged
                      keys: ["image"]
                      a_min: "$@CONSTANTS#intensity_range[0]"
                      a_max: "$@CONSTANTS#intensity_range[1]"
                      b_min: 0
                      b_max: 1
                      clip: True
                    # Flip for the dataet 
                    - _target_: monai.transforms.Lambdad
                      keys: ["image"]
                      func: "@CONSTANTS#dataset_specific_transform"
                    - _target_: monai.transforms.CropForegroundd
                      source_key: "image"
                      keys: ["image"]
                      margin: 10
                    - _target_:   monai.transforms.Resized
                      keys: ["image"]
                      spatial_size: "@CONSTANTS#size"
                      mode: "bilinear"
                    - _target_: monai.transforms.RandAffined
                      keys: ["image"]
                      prob: 0.2
                      rotate_range: [0.26, 0.26, 0.26]
                      scale_range: [0.2, 0.2, 0.2]
                      cache_grid: True
                      padding_mode: constant
                    - _target_: monai.transforms.RandGaussianSmoothd
                      keys: ["image"]
                      prob: 0.2
                      sigma_x: [0.5, 1.0]
                      sigma_y: [0.5, 1.0]
                      sigma_z: [0.5, 1.0]
                    - _target_: monai.transforms.RandScaleIntensityd
                      keys: ["image"]
                      factors: 0.3
                      prob: 0.5
                    - _target_: monai.transforms.RandShiftIntensityd
                      keys: ["image"]
                      offsets: 0.1
                      prob: 0.5
                    - _target_: monai.transforms.RandGaussianNoised
                      keys: ["image"]
                      std: 0.1
                      prob: 0.2
                    - _target_: monai.transforms.Lambda
                      func: '$lambda x: {"input": x["image"].as_tensor(), "target": x["label"].as_tensor().to(dtype=torch.float32)}'
                      track_meta: False

        val: 
            _target_: monai.data.PersistentDataset
            data:
                _target_: project.data.radchest_get_image_label_paths
                data_dir: "%CONSTANTS#dataset_dir"
                split: val            
            cache_dir: '$f"{@CONSTANTS#cache_dir}/val"'
            hash_transform: "$monai.data.utils.json_hashing"
            transform: 
                _target_: monai.transforms.Compose
                transforms: 
                    - _target_: monai.transforms.LoadImaged
                      reader: "NumpyReader"
                      keys: ["image"]
                      npz_keys: ["ct"]
                    - _target_: monai.transforms.ToTensord
                      keys: ["image", "label"]
                    - _target_: monai.transforms.EnsureChannelFirstd
                      keys: ["image"]
                    - _target_: monai.transforms.EnsureTyped
                      keys: ["image"]
                    - _target_: monai.transforms.ScaleIntensityRanged
                      keys: ["image"]
                      a_min: "$@CONSTANTS#intensity_range[0]"
                      a_max: "$@CONSTANTS#intensity_range[1]"
                      b_min: 0
                      b_max: 1
                      clip: True
                    # Flip for the dataet 
                    - _target_: monai.transforms.Lambdad
                      keys: ["image"]
                      func: "@CONSTANTS#dataset_specific_transform"
                    - _target_: monai.transforms.CropForegroundd
                      source_key: "image"
                      keys: ["image"]
                      margin: 10
                    - _target_:   monai.transforms.Resized
                      keys: ["image"]
                      spatial_size: "@CONSTANTS#size"
                      mode: "bilinear"
                    - _target_: monai.transforms.Lambda
                      func: '$lambda x: {"input": x["image"].as_tensor(), "target": x["label"].as_tensor().to(dtype=torch.float32)}'
                      track_meta: False
                                  
    postprocessing:
        metrics:
            pred: # Pred for torchmetrics is (N, C, ...)
                - "$lambda x: torch.sigmoid(x)"

            target:
                # Remove the channel dim. Target for torchmetrics is (N, ...)
                - "$lambda tensor: tensor.long()"
        logging:              
            pred:
                - "$lambda x: x.argmax(dim=1, keepdim=True)"
                - "$lambda x: x.float()"
            target:
                - "$lambda x: x.unsqueeze(1)"
                - "$lambda x: x.float()"